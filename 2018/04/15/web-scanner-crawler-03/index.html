<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 爬虫调度篇[Web 漏洞扫描器] · fate0</title><meta name="description" content="爬虫调度篇[Web 漏洞扫描器] - fate0"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://blog.fatezero.org/atom.xml" title="fate0"><script>var _hmt = _hmt || [];
(function() {
var hm = document.createElement("script");
hm.src = "https://hm.baidu.com/hm.js?345ca1db7809172aec8db3a78e7679c4";
var s = document.getElementsByTagName("script")[0]; 
s.parentNode.insertBefore(hm, s);
})();</script></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://www.fatezero.org" target="_blank" class="nav-list-link">ABOUT</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">爬虫调度篇[Web 漏洞扫描器]</h1><div class="post-info">Apr 15, 2018</div><div class="post-content"><h2 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h2><p><a href="http://blog.fatezero.org/2018/03/05/web-scanner-crawler-02/">上一篇</a>主要如何通过向浏览器页面注入 JavaScript 代码来尽可能地获取页面上的链接信息，最后完成一个稳定可靠的单页面链接信息抓取组件。这一篇我们跳到一个更大的世界，看一下整个漏扫爬虫的运转流程，这一篇会着重描写爬虫架构设计以及调度部分。</p>
<a id="more"></a>
<h2 id="0x01-设计"><a href="#0x01-设计" class="headerlink" title="0x01 设计"></a>0x01 设计</h2><img src="http://static.fatezero.org/blog/img/web-scanner-crawler-03/scrapy_architecture_02.png">
<p>这张图片是不是很熟悉，其实这就是 <code>Scrapy</code> 的架构设计图，我们简单看一下这张图的流程：</p>
<ol>
<li><code>Engine</code> 拿到 <code>Requests</code></li>
<li><code>Engine</code> 将 <code>Requests</code> 丢到 <code>Scheduler</code> 中，并向 <code>Scheduler</code> 请求下一个准备抓取的 <code>Request</code></li>
<li><code>Scheduler</code> 返回下一个准备抓取的 <code>Request</code></li>
<li><code>Engine</code> 将 <code>Request</code> 丢到 <code>Downloader</code> 中，中途经过 <code>Downloader Middlewares</code> 处理</li>
<li><code>Downloader</code> 处理 <code>Request</code> 产生 <code>Response</code> 返回给 <code>Engine</code>，中途经过 <code>Downloader Middlewares</code> 处理</li>
<li><code>Engine</code> 将 <code>Response</code> 丢到 <code>Spider</code> 中，中途经过 <code>Spider Middleware</code> 处理</li>
<li><code>Spider</code> 处理 <code>Response</code> 产生出 <code>item</code> 和新的 <code>Requests</code> 返回给 <code>Engine</code>，中途经过 <code>Spider Middleware</code> 处理</li>
<li><code>Engine</code> 将 <code>item</code> 丢到 <code>Item Pipelines</code> 处理，同时将 <code>Requests</code> 丢到 <code>Scheduler</code> 中</li>
<li>重复 1-8 步骤，直到 <code>Scheduler</code> 没有新的 <code>Requests</code></li>
</ol>
<p>在整体架构上我直接参考了 <code>Scrapy</code> 的设计，只不过我实在受不了 <code>Twisted</code> 那种扭曲的写法，
所以直接换了个网络库重新造了个和 <code>Scrapy</code> 差不多的轮子，新的架构图如下：</p>
<img src="http://static.fatezero.org/blog/img/web-scanner-crawler-03/caster_spider_architecture.png">
<p>上面架构图中消息队列(<code>MQ</code>)左边的内部名为 <code>CasterPy</code>，右边的内部名为 <code>CasterJS</code>， 
我们前两篇主要介绍的单页面链接信息抓取组件(<code>CasterJS</code>)就是上面的架构设计中的 <code>Downloader</code>，
我们的架构设计和 <code>Scrapy</code> 的区别是：</p>
<ul>
<li>我们的 <code>Downloader</code> 直接返回链接信息而不是返回响应内容</li>
<li>我们的 <code>Downloader</code> 是分布式的，可部署在不同的服务器上</li>
<li>我们的 <code>Engine</code> 通过消息队列与 <code>Downloader</code> 通信</li>
<li>我们的 <code>Downloader</code> 针对同一个站点并发数始终为 1</li>
<li>我们的 <code>CasterPy</code> 使用协程同时处理多个站点，可同时和多个 <code>Downloader</code> 进行通信</li>
</ul>
<p>我们的 <code>Spider</code> 组件也只是简单的解析链接信息返回相对应的 <code>item</code> 和新的 <code>Request</code>，这部分没什么好讲的，
我们的 <code>Engine</code> 组件和 <code>Scrapy</code> 的也差不多，就是 <code>Item</code>、<code>Request</code>、<code>Response</code> 的搬运工，这部分也不用细讲，
至于 <code>Item Pipelines</code>，最后数据怎么存储、存储到哪里去，每家公司都有自己的想法（每家公司的想法差距都挺大的），这个就仁者见仁，
剩下就只有 <code>Scheduler</code> 了。</p>
<h2 id="0x02-调度"><a href="#0x02-调度" class="headerlink" title="0x02 调度"></a>0x02 调度</h2><p><code>Scheduler</code> 决定了 <code>Request</code> 的优先级、去留，漏扫爬虫的 <code>Scheduler</code> 和普通爬虫的 <code>Scheduler</code> 最大的区别是如何决定 <code>Request</code> 的去留，也就是爬虫的去重问题。</p>
<p>去重真的是我在写漏扫爬虫除了 <code>QtWebkit</code> 之外最头疼的事情了。针对漏扫爬虫的去重，完全就没有什么比较好的公开的策略去处理，
老生常谈的 <code>Bloom Filter</code> 在漏扫爬虫中毫无用武之地。</p>
<p>普通爬虫一般来说只会丢弃非目标、已爬取的 <code>Request</code>，但在漏扫爬虫中完全不能只做这些，
因为这样不仅会浪费爬虫的资源，也会浪费后续检测的资源，所以我们需要自己造一个去重策略对 <code>Request</code> 进行更深层次的去重。</p>
<h4 id="资源去重"><a href="#资源去重" class="headerlink" title="资源去重"></a>资源去重</h4><p>我们在使用 Chromium 加载一个页面的时候，Chromium 会对网络资源做分类，这些分类主要有：</p>
<img src="http://static.fatezero.org/blog/img/web-scanner-crawler-03/chromium_resource_type.png" width="500">
<p>我们在之前注入的 JavaScript 代码在获取链接信息的时候也采取了这样的分类(虽然我之前没讲=。=)，那很明显，我们只需要对 <code>Doc</code> 类型的 <code>Request</code> 进行再入 download 队列，其他资源都没必要再使用浏览器再下载渲染一遍。</p>
<h4 id="链接去重"><a href="#链接去重" class="headerlink" title="链接去重"></a>链接去重</h4><p>在最初的几年前在头疼去重这个问题的时候，剑心和我讨论的结果是可以把 request 中的参数分为 <code>action</code> 类型和 <code>data</code> 类型：</p>
<ul>
<li><code>action</code> 类型: 对代码逻辑产生影响的参数</li>
<li><code>data</code> 类型: 在代码中作为数据使用，一般不会影响到代码逻辑的参数</li>
</ul>
<p>简单的讲，<code>action</code> 类型的参数就是语言 vm 中 opcode，<code>data</code> 类型就是语言 vm 中的操作数，
我们就是希望能够从 request 数据中分析出哪些是 <code>action</code> 类型的参数，哪些是 <code>data</code> 类型的参数，然后再进行去重。</p>
<p>我们看个简单的例子：
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> ($_GET[<span class="string">'a'</span>] == <span class="string">'create'</span>) &#123;</span><br><span class="line">    mysql_query(<span class="string">"INSERT INTO test VALUES ('$_GET['b']')"</span>, $conn);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>其中 <code>a</code> 就是属于 <code>action</code> 类型的参数，因为 <code>a</code> 的值必须是 <code>create</code> 才会有数据库操作的逻辑。
<code>b</code> 属于 <code>data</code> 类型的参数，因为 <code>b</code> 的值无关紧要，不会影响到代码执行逻辑。</p>
<p>从代码中很容易分析出参数的类型，可是仅仅从 url 中怎么区别参数类型呢？
这个时候我们就需要从开发人员写代码的心理去推测参数类型了。</p>
<p>首先一般开发人员不会使用中文作为 <code>action</code> 类型参数的值，很难想象会有人这样写代码：
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> ($_GET[<span class="string">'a'</span>] == <span class="string">'创建'</span>) &#123; <span class="comment">/* do create stuff */</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>所以带中文字符的参数，可以直接被认为是 <code>data</code> 类型的参数。</p>
<p>其次一般开发人员的不会使用超过 2 位的纯数字作为 <code>action</code> 类型的值：
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> ($_GET[<span class="string">'a'</span>] == <span class="string">'87'</span>) &#123; <span class="comment">/* do create stuff */</span> &#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> ($_GET[<span class="string">'a'</span>] == <span class="string">'9527'</span>) &#123; <span class="comment">/*do delete stuff */</span> &#125;</span><br></pre></td></tr></table></figure></p>
<p>再次一般开发人员也不会使用 HASH/UUID 值作为 <code>action</code> 类型的值：
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> ($_GET[<span class="string">'a'</span>] == <span class="string">'f95df1d4d3c89392f1fd920787bb7303'</span>) &#123;&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> ($_GET[<span class="string">'a'</span>] == <span class="string">'f95df1d4-d3c8-9392-f1fd-920787bb7303'</span>) &#123;&#125;</span><br></pre></td></tr></table></figure></p>
<p>还记得<a href="">上一篇</a>我们提到自动化填写表单的时候，最好能够自定义输入的地方都填上带 <code>casterjs</code> 字符吗？
就是为了能够在这里直接区分出带 <code>casterjs</code> 值的参数都是 <code>data</code> 类型参数。</p>
<p>最后一般开发人员也不会使用 … (自由想象、发挥、总结规律)</p>
<p>其实我们这个过程就是在猜，猜测一个正常的开发人员的编码规范。
前期通过各种猜测，我们可以对下面这些类型的 url 简单去重：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://fatezero.org/test?a=create&amp;b=你好</span><br><span class="line">http://fatezero.org/test?a=create&amp;b=3721</span><br><span class="line">http://fatezero.org/test?a=create&amp;b=casterjs@gmail.com</span><br><span class="line">http://fatezero.org/test?a=create&amp;b=f95df1d4d3c89392f1fd920787bb7303</span><br></pre></td></tr></table></figure>
<p>因为上面的参数 <code>b</code> 被识别成 <code>data</code> 类型参数，所以理论上 <code>b</code> 的值被替换成什么都无所谓，
我们将 <code>data</code> 类型参数的值替换成 <code>{ { data }}</code> 得到 “临时规则”：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://fatezero.org/test?a=create&amp;b=&#123;&#123;data&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>上面这些去重步骤仅仅是第一步，接下来我们还要考虑下面这种情况：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://fatezero.org/test?a=create&amp;b=halo</span><br><span class="line">http://fatezero.org/test?a=create&amp;b=hello</span><br><span class="line">http://fatezero.org/test?a=create&amp;b=你好</span><br><span class="line">http://fatezero.org/test?a=create&amp;b=3721</span><br><span class="line">http://fatezero.org/test?a=create&amp;b=casterjs@gmail.com</span><br><span class="line">http://fatezero.org/test?a=create&amp;b=f95df1d4d3c89392f1fd920787bb7303</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>通过第一步简单替换之后，得到 “临时规则”：
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. http://fatezero.org/test?a=create&amp;b=halo</span><br><span class="line">2. http://fatezero.org/test?a=create&amp;b=hello</span><br><span class="line">3. http://fatezero.org/test?a=create&amp;b=&#123;&#123;data&#125;&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>这样的结果我们并不是特别满意，但通过第一步简单替换也只能得到这样的结果了。但随着第三条 “临时规则” 命中的 url 越来越多，
我们就越有理由相信参数 <code>b</code> 就是 <code>data</code> 类型的参数，参数 <code>a</code> 就是 <code>action</code> 类型的参数，
所以刚刚得到的 “临时规则” 在命中次数达到我们所设定的一个阈值后，还可以变成 “最后规则” ：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://fatezero.org/test?a=create&amp;b=&#123;%data%&#125;</span><br></pre></td></tr></table></figure>
<p>上面这条就是去重过程中生成的去重 “最后规则”，根据这条 “最后规则” 我们又可以直接对下面的链接直接去重：
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://fatezero.org/test?a=create&amp;b=nihao</span><br><span class="line">http://fatezero.org/test?a=create&amp;b=world</span><br><span class="line">http://fatezero.org/test?a=create&amp;b=create</span><br></pre></td></tr></table></figure></p>
<p>“临时规则” 只有统计的作用，并不能参与去重复步骤，但是 “最后规则” 可以参与去重。就如同刚才所示，”临时规则” 可以发展成 “最后规则”。
在 <code>Scheduler</code> 去重中，我们最希望拿到的并不是 url，而是实时在变化的去重规则，通过越来越多的 url 生成越来越精准的去重规则，
再通过越来越精准的规则反过来再对以后以及之前的 url 进行去重，得到重复度越来越低的 url，这就是我们造的去重策略。</p>
<h4 id="URL-Rewrite-去重"><a href="#URL-Rewrite-去重" class="headerlink" title="URL Rewrite 去重"></a>URL Rewrite 去重</h4><p>前面我们根据猜测开发人员心理去制定去重策略，这里我们还需要继续猜测 URL Rewrite 配置人员的心理去完善我们的去重策略。</p>
<p>我们先看一下几种常规的 URL Rewrite 之后 url 的样子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://fatezero.org/view/123.html</span><br><span class="line">http://fatezero.org/view-123.html</span><br><span class="line">http://fatezero.org/view_123.html</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>我们先假设上面的 <code>view</code> 就是我们所说的 <code>action</code> 类型参数，<code>123</code> 就是 <code>data</code> 类型参数，
针对 URL Rewrite 之后的 url，我们首先应该找到各个参数之间的间隔符号是什么，上面的例子中参数间隔符号分别是 <code>/</code>、<code>-</code>、<code>_</code>，
然后以根路径开始，用 1、2、3 顺序作为 key，对应 path 深度的值作为 value，最终还是可以直接转换成 <code>key-value</code> 格式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://fatezero.org/?1=view&amp;2=123</span><br></pre></td></tr></table></figure>
<p>最后还是通过之前的去重策略进行去重，发现了么，漏扫去重这块大多数时候都只能猜测，并没有一个万能的解决方法。</p>
<h2 id="0x03-测试"><a href="#0x03-测试" class="headerlink" title="0x03 测试"></a>0x03 测试</h2><p>经过简单的测试，在 2 核 4G 内存服务器上能同时跑 50 个 Chromium Tab，
在 4 核 8G 内存服务器上一个 <code>CasterPy</code> 能够同时跑 1000 个任务，
也就是说一台 <code>CasterPy</code> 服务器可以和 20 台 <code>CasterJS</code> 服务器构成一个小规模的爬虫。
如果任务并发数增加，那也得相对应增加 <code>CasterPy</code> 服务器的资源以及 <code>CasterJS</code> 服务器的数量了。</p>
<h2 id="0x04-总结"><a href="#0x04-总结" class="headerlink" title="0x04 总结"></a>0x04 总结</h2><p>至此，扫描器中爬虫部分就算简单地过了一遍，虽然讲得比较粗略，但不管怎么样也得切到下一个话题了。</p>
<p><a href="#">下一篇</a>我们讲一下 Web 漏洞扫描器中漏洞检测技巧部分。</p>
</div></article></div></main><footer><div class="paginator"><a href="/2018/11/11/prvd/" class="prev">PREV</a><a href="/2018/04/09/web-scanner-crawler-02/" class="next">NEXT</a></div><div class="copyright"><p>© 2016 - 2018 <a href="http://blog.fatezero.org">fate0</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">apollo</a>.</p></div></footer></div></body></html>